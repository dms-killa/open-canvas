# Local Ollama (Primary Provider)
OLLAMA_API_URL=http://localhost:11434
OLLAMA_CHAT_MODEL=llama3

# Optional: LiteLLM Proxy
# LITELLM_BASE_URL=http://host.docker.internal:4000

# Optional: Cloud Providers
# ANTHROPIC_API_KEY=""
# OPENAI_API_KEY=""

# Optional: LangChain Tracing
# LANGCHAIN_TRACING_V2="false"
# LANGCHAIN_API_KEY=""

# Database
DATABASE_URL="postgresql://opencanvas:opencanvas_local@localhost:5432/opencanvas"

# Optional: Smoke test mode
# OPEN_CANVAS_SMOKE=1